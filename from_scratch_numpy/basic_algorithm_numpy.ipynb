{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST Rakam Tanıma: Yapay Sinir Ağı Implementasyonu ve Analizi\n",
        "\n",
        "Bu belge, MNIST veri seti üzerinde sıfırdan bir yapay sinir ağı (Neural Network) implementasyonunu, değerlendirmesini ve görselleştirmesini içermektedir. Tüm süreç adım adım açıklanmıştır. Sinir ağı çalışma mantığı numpy ile işin matematiğine değinerek eğitilmiştir.\n",
        "\n",
        "## 1. Gerekli Kütüphanelerin İçe Aktarılması"
      ],
      "metadata": {
        "id": "Y6HvK12hQoBF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kk7O74MoQbxD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu kod bloğunda, projemiz için gerekli olan kütüphaneleri içe aktarıyoruz:\n",
        "- `numpy`: Matematiksel işlemler ve dizi (array) manipülasyonu için\n",
        "- `tensorflow` ve ilgili modüller: MNIST veri setini yüklemek ve kategori dönüşümleri için\n",
        "- `sklearn` modülleri: Veri bölme ve performans metriklerini hesaplamak için\n",
        "- `matplotlib` ve `seaborn`: Veri görselleştirme için\n",
        "\n",
        "## 2. Aktivasyon Fonksiyonlarının Tanımlanması"
      ],
      "metadata": {
        "id": "I4ji2DMBQsoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def relu_derivative(x):\n",
        "    return (x > 0).astype(float)\n",
        "\n",
        "def softmax(x):\n",
        "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)"
      ],
      "metadata": {
        "id": "SZM5TNXFQv_w"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yapay sinir ağımızda kullanacağımız aktivasyon fonksiyonlarını tanımlıyoruz:\n",
        "- `relu`: Gizli katman için Rectified Linear Unit aktivasyon fonksiyonu\n",
        "- `relu_derivative`: Geri yayılım (backpropagation) için ReLU'nun türevi\n",
        "- `softmax`: Çıkış katmanı için olasılık dağılımı oluşturan aktivasyon fonksiyonu\n",
        "\n",
        "ReLU fonksiyonu, giriş değeri 0'dan büyükse girişi olduğu gibi döndürür, değilse 0 döndürür. Softmax fonksiyonu ise tüm çıkışların toplamının 1 olacağı şekilde bir olasılık dağılımı oluşturur.\n",
        "\n",
        "## 3. Performans Metriklerini Hesaplama Fonksiyonu"
      ],
      "metadata": {
        "id": "NpazqZIKQxyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_metrics(y_true, y_pred):\n",
        "    y_true_class = np.argmax(y_true, axis=1)\n",
        "    y_pred_class = np.argmax(y_pred, axis=1)\n",
        "\n",
        "    # Sınıf bazında precision ve recall\n",
        "    precision = precision_score(y_true_class, y_pred_class, average='macro')\n",
        "    recall = recall_score(y_true_class, y_pred_class, average='macro')\n",
        "    f1 = f1_score(y_true_class, y_pred_class, average='macro')\n",
        "\n",
        "    return precision, recall, f1"
      ],
      "metadata": {
        "id": "pde7olhBQuK-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu fonksiyon, modelin performansını değerlendirmek için üç önemli metriği hesaplar:\n",
        "- `precision`: Modelin pozitif olarak tahmin ettiği örnekler içinde gerçekten pozitif olanların oranı\n",
        "- `recall`: Gerçekte pozitif olan örnekler içinde modelin pozitif olarak tahmin ettiği örneklerin oranı\n",
        "- `f1`: Precision ve recall'un harmonik ortalaması\n",
        "\n",
        "\"macro\" ortalama, her sınıfın eşit ağırlıkta hesaba katıldığı anlamına gelir.\n",
        "\n",
        "## 4. Veri Setinin Yüklenmesi ve Ön İşleme"
      ],
      "metadata": {
        "id": "8_otgyFoQyVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST Veri Setini Yükleme\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalizasyon ve Dönüştürme\n",
        "x_train = x_train.reshape(-1, 784) / 255.0\n",
        "x_test = x_test.reshape(-1, 784) / 255.0\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Eğitim Setini Validation İçin Bölme (%80 eğitim, %20 validasyon)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XBIpLebQynn",
        "outputId": "f17b1e9f-ef70-4fd0-bedc-774b132742d4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu kod bloğunda:\n",
        "1. MNIST veri setini TensorFlow aracılığıyla yüklüyoruz\n",
        "2. Görüntüleri düzleştiriyor (28x28 -> 784) ve 0-1 aralığına normalize ediyoruz\n",
        "3. Etiketleri one-hot encoding formatına dönüştürüyoruz\n",
        "4. Eğitim verilerini %80 eğitim, %20 doğrulama olacak şekilde ayırıyoruz\n",
        "\n",
        "## 5. Model Parametrelerinin Başlatılması"
      ],
      "metadata": {
        "id": "Cy2CSAYSQy2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Ağırlıklarını Başlatma\n",
        "input_size = 784\n",
        "hidden_size = 128\n",
        "output_size = 10\n",
        "learning_rate = 0.01\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "W1 = np.random.randn(input_size, hidden_size) * 0.01\n",
        "b1 = np.zeros((1, hidden_size))\n",
        "W2 = np.random.randn(hidden_size, output_size) * 0.01\n",
        "b2 = np.zeros((1, output_size))\n",
        "\n",
        "# Metrik takibi için listeler\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "val_accuracies = []\n",
        "val_precisions = []\n",
        "val_recalls = []\n",
        "val_f1s = []"
      ],
      "metadata": {
        "id": "Aod3gFVoQzJm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu kısımda:\n",
        "1. Modelin hiperparametrelerini tanımlıyoruz (girişler, gizli katman boyutu, çıkışlar, öğrenme oranı)\n",
        "2. Ağırlıkları (W1, W2) küçük rastgele değerlerle, bias'ları (b1, b2) sıfırla başlatıyoruz\n",
        "3. Eğitim sırasında metrikleri takip etmek için boş listeler oluşturuyoruz\n",
        "\n",
        "## 6. Model Eğitimi ve Metrik Hesaplaması"
      ],
      "metadata": {
        "id": "xViJOWUEQzWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Eğitim Döngüsü\n",
        "for epoch in range(epochs):\n",
        "    epoch_losses = []\n",
        "\n",
        "    # Mini-batch training\n",
        "    for i in range(0, x_train.shape[0], batch_size):\n",
        "        x_batch = x_train[i:i+batch_size]\n",
        "        y_batch = y_train[i:i+batch_size]\n",
        "\n",
        "        # İleri Yayılım\n",
        "        Z1 = np.dot(x_batch, W1) + b1\n",
        "        A1 = relu(Z1)\n",
        "        Z2 = np.dot(A1, W2) + b2\n",
        "        A2 = softmax(Z2)\n",
        "\n",
        "        # Kayıp (Cross-Entropy)\n",
        "        loss = -np.sum(y_batch * np.log(A2 + 1e-8)) / batch_size\n",
        "        epoch_losses.append(loss)\n",
        "\n",
        "        # Geri Yayılım\n",
        "        dZ2 = A2 - y_batch\n",
        "        dW2 = np.dot(A1.T, dZ2) / batch_size\n",
        "        db2 = np.sum(dZ2, axis=0, keepdims=True) / batch_size\n",
        "\n",
        "        dZ1 = np.dot(dZ2, W2.T) * relu_derivative(Z1)\n",
        "        dW1 = np.dot(x_batch.T, dZ1) / batch_size\n",
        "        db1 = np.sum(dZ1, axis=0, keepdims=True) / batch_size\n",
        "\n",
        "        # Ağırlık Güncelleme\n",
        "        W2 -= learning_rate * dW2\n",
        "        b2 -= learning_rate * db2\n",
        "        W1 -= learning_rate * dW1\n",
        "        b1 -= learning_rate * db1\n",
        "\n",
        "    # Epoch ortalama kaybı\n",
        "    avg_train_loss = np.mean(epoch_losses)\n",
        "    train_losses.append(avg_train_loss)\n",
        "\n",
        "    # Her Epoch Sonunda Validation Kaybı ve Metrikleri Hesapla\n",
        "    Z1_val = np.dot(x_val, W1) + b1\n",
        "    A1_val = relu(Z1_val)\n",
        "    Z2_val = np.dot(A1_val, W2) + b2\n",
        "    A2_val = softmax(Z2_val)\n",
        "\n",
        "    val_loss = -np.sum(y_val * np.log(A2_val + 1e-8)) / x_val.shape[0]\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    val_accuracy = np.mean(np.argmax(A2_val, axis=1) == np.argmax(y_val, axis=1))\n",
        "    val_accuracies.append(val_accuracy)\n",
        "\n",
        "    # Precision ve Recall hesaplama\n",
        "    val_precision, val_recall, val_f1 = calculate_metrics(y_val, A2_val)\n",
        "    val_precisions.append(val_precision)\n",
        "    val_recalls.append(val_recall)\n",
        "    val_f1s.append(val_f1)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {avg_train_loss:.4f} - Val Loss: {val_loss:.4f} - Val Accuracy: {val_accuracy:.4f}\")\n",
        "    print(f\"Validation Metrics - Precision: {val_precision:.4f} - Recall: {val_recall:.4f} - F1 Score: {val_f1:.4f}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quz6JZ4mRBs5",
        "outputId": "4c988a08-de60-4d85-8a67-c38e764123da"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 - Loss: 1.4315 - Val Loss: 0.6102 - Val Accuracy: 0.8415\n",
            "Validation Metrics - Precision: 0.8424 - Recall: 0.8387 - F1 Score: 0.8384\n",
            "\n",
            "Epoch 2/10 - Loss: 0.4835 - Val Loss: 0.4046 - Val Accuracy: 0.8882\n",
            "Validation Metrics - Precision: 0.8869 - Recall: 0.8867 - F1 Score: 0.8865\n",
            "\n",
            "Epoch 3/10 - Loss: 0.3775 - Val Loss: 0.3478 - Val Accuracy: 0.9038\n",
            "Validation Metrics - Precision: 0.9027 - Recall: 0.9026 - F1 Score: 0.9024\n",
            "\n",
            "Epoch 4/10 - Loss: 0.3366 - Val Loss: 0.3186 - Val Accuracy: 0.9116\n",
            "Validation Metrics - Precision: 0.9106 - Recall: 0.9106 - F1 Score: 0.9104\n",
            "\n",
            "Epoch 5/10 - Loss: 0.3111 - Val Loss: 0.2985 - Val Accuracy: 0.9166\n",
            "Validation Metrics - Precision: 0.9157 - Recall: 0.9157 - F1 Score: 0.9155\n",
            "\n",
            "Epoch 6/10 - Loss: 0.2916 - Val Loss: 0.2822 - Val Accuracy: 0.9213\n",
            "Validation Metrics - Precision: 0.9205 - Recall: 0.9204 - F1 Score: 0.9203\n",
            "\n",
            "Epoch 7/10 - Loss: 0.2751 - Val Loss: 0.2682 - Val Accuracy: 0.9247\n",
            "Validation Metrics - Precision: 0.9240 - Recall: 0.9239 - F1 Score: 0.9238\n",
            "\n",
            "Epoch 8/10 - Loss: 0.2607 - Val Loss: 0.2559 - Val Accuracy: 0.9291\n",
            "Validation Metrics - Precision: 0.9285 - Recall: 0.9284 - F1 Score: 0.9283\n",
            "\n",
            "Epoch 9/10 - Loss: 0.2477 - Val Loss: 0.2450 - Val Accuracy: 0.9321\n",
            "Validation Metrics - Precision: 0.9316 - Recall: 0.9314 - F1 Score: 0.9314\n",
            "\n",
            "Epoch 10/10 - Loss: 0.2361 - Val Loss: 0.2352 - Val Accuracy: 0.9352\n",
            "Validation Metrics - Precision: 0.9347 - Recall: 0.9346 - F1 Score: 0.9345\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu eğitim döngüsü:\n",
        "1. Her epoch içinde veriyi mini-batch'lere böler\n",
        "2. Her mini-batch için:\n",
        "   - **İleri Yayılım (Forward Propagation)**: Giriş verilerini ağ üzerinden ileterek tahminler üretir\n",
        "   - **Kayıp Hesaplama**: Cross-entropy kayıp fonksiyonu ile tahmin hatasını ölçer\n",
        "   - **Geri Yayılım (Backpropagation)**: Gradyanları hesaplayarak hatanın kaynağını bulur\n",
        "   - **Ağırlık Güncelleme**: Gradyan inişi ile model parametrelerini günceller\n",
        "3. Her epoch sonunda ortalama eğitim kaybını kaydeder\n",
        "\n",
        "Bu kod bloğu her epoch sonunda:\n",
        "1. Doğrulama veri seti üzerinde ileri yayılım gerçekleştirir\n",
        "2. Doğrulama kaybını ve doğruluk oranını hesaplar\n",
        "3. Precision, recall ve F1 skorlarını hesaplar\n",
        "4. Tüm metrikleri ilgili listelere kaydeder ve ekrana yazdırır\n",
        "\n",
        "Bu işlem, modelin eğitim verileri dışındaki performansını izlememizi sağlar.\n",
        "\n",
        "## 7. Test Seti Değerlendirmesi"
      ],
      "metadata": {
        "id": "jdLykVC_RGPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelin Test Edilmesi\n",
        "Z1_test = np.dot(x_test, W1) + b1\n",
        "A1_test = relu(Z1_test)\n",
        "Z2_test = np.dot(A1_test, W2) + b2\n",
        "A2_test = softmax(Z2_test)\n",
        "\n",
        "test_accuracy = np.mean(np.argmax(A2_test, axis=1) == np.argmax(y_test, axis=1))\n",
        "test_precision, test_recall, test_f1 = calculate_metrics(y_test, A2_test)\n",
        "\n",
        "print(f\"\\nTest Sonuçları:\")\n",
        "print(f\"Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Precision: {test_precision:.4f}\")\n",
        "print(f\"Recall: {test_recall:.4f}\")\n",
        "print(f\"F1 Score: {test_f1:.4f}\")\n",
        "\n",
        "# Confuion Matrix hesaplama\n",
        "y_true_class = np.argmax(y_test, axis=1)\n",
        "y_pred_class = np.argmax(A2_test, axis=1)\n",
        "\n",
        "# Her sınıf için precision ve recall hesaplama (detaylı analiz)\n",
        "class_precision = precision_score(y_true_class, y_pred_class, average=None)\n",
        "class_recall = recall_score(y_true_class, y_pred_class, average=None)\n",
        "\n",
        "print(f\"\\nSınıf Bazında Metrikler:\")\n",
        "for i in range(10):\n",
        "    print(f\"Sınıf {i} - Precision: {class_precision[i]:.4f} - Recall: {class_recall[i]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPl04YaZRDyZ",
        "outputId": "059c4e56-9aa3-4523-f159-1e343e7aa6d6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Sonuçları:\n",
            "Accuracy: 0.9350\n",
            "Precision: 0.9346\n",
            "Recall: 0.9340\n",
            "F1 Score: 0.9340\n",
            "\n",
            "Sınıf Bazında Metrikler:\n",
            "Sınıf 0 - Precision: 0.9450 - Recall: 0.9827\n",
            "Sınıf 1 - Precision: 0.9712 - Recall: 0.9797\n",
            "Sınıf 2 - Precision: 0.9317 - Recall: 0.9254\n",
            "Sınıf 3 - Precision: 0.9069 - Recall: 0.9356\n",
            "Sınıf 4 - Precision: 0.9168 - Recall: 0.9430\n",
            "Sınıf 5 - Precision: 0.9399 - Recall: 0.8767\n",
            "Sınıf 6 - Precision: 0.9237 - Recall: 0.9603\n",
            "Sınıf 7 - Precision: 0.9538 - Recall: 0.9232\n",
            "Sınıf 8 - Precision: 0.9286 - Recall: 0.9076\n",
            "Sınıf 9 - Precision: 0.9289 - Recall: 0.9058\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eğitim tamamlandıktan sonra bu kod:\n",
        "1. Test veri seti üzerinde modelin performansını değerlendirir\n",
        "2. Genel doğruluk, precision, recall ve F1 skorlarını hesaplar\n",
        "3. Her rakam sınıfı (0-9) için ayrı ayrı precision ve recall değerlerini hesaplar\n",
        "4. Tüm sonuçları ekrana yazdırır\n",
        "\n",
        "Bu kısım, modelin gerçek dünya verileri üzerindeki performansının en iyi göstergesidir."
      ],
      "metadata": {
        "id": "vNR9ZwtWRJ1y"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WQb_fcH5RIo4"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}